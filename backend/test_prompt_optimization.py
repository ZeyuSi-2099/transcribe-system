"""
Promptä¼˜åŒ–æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸åŒåœºæ™¯å’Œè§„åˆ™é…ç½®çš„è½¬æ¢æ•ˆæœ
"""

import asyncio
import json
import httpx
from typing import Dict, List


class PromptOptimizationTester:
    """Promptä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://127.0.0.1:8000"):
        self.base_url = base_url
        self.test_cases = self._init_test_cases()
        self.rule_combinations = self._init_rule_combinations()
    
    def _init_test_cases(self) -> List[Dict]:
        """åˆå§‹åŒ–æµ‹è¯•ç”¨ä¾‹"""
        return [
            {
                "name": "å·¥ä½œè®¿è°ˆ",
                "text": """é—®ï¼šè¯·ä»‹ç»ä¸€ä¸‹ä½ çš„å·¥ä½œç»å†ã€‚
ç­”ï¼šæˆ‘ä»2020å¹´å¼€å§‹åœ¨ä¸€å®¶ç§‘æŠ€å…¬å¸å·¥ä½œï¼Œä¸»è¦è´Ÿè´£äº§å“è®¾è®¡ã€‚ä¹‹å‰åœ¨å¤§å­¦é‡Œå­¦çš„æ˜¯è®¡ç®—æœºä¸“ä¸šï¼Œæ¯•ä¸šåå°±ç›´æ¥è¿›å…¥äº†è¿™ä¸ªè¡Œä¸šã€‚
é—®ï¼šåœ¨å·¥ä½œä¸­é‡åˆ°è¿‡ä»€ä¹ˆæŒ‘æˆ˜å—ï¼Ÿ
ç­”ï¼šæœ€å¤§çš„æŒ‘æˆ˜æ˜¯éœ€è¦ä¸æ–­å­¦ä¹ æ–°æŠ€æœ¯ï¼Œå› ä¸ºç§‘æŠ€è¡Œä¸šå˜åŒ–å¾ˆå¿«ã€‚è¿˜æœ‰å°±æ˜¯è¦å’Œä¸åŒéƒ¨é—¨çš„åŒäº‹åä½œï¼Œæœ‰æ—¶å€™æ²Ÿé€šæˆæœ¬æ¯”è¾ƒé«˜ã€‚""",
                "expected_type": "interview"
            },
            {
                "name": "æ—¥å¸¸å¯¹è¯",
                "text": """é—®ï¼šä½ æ˜¨å¤©æ™šä¸Šåšäº†ä»€ä¹ˆï¼Ÿ
ç­”ï¼šæˆ‘åœ¨å®¶çœ‹äº†éƒ¨ç”µå½±ï¼Œç„¶åæ—©ç‚¹ç¡äº†ã€‚
é—®ï¼šçœ‹çš„ä»€ä¹ˆç”µå½±ï¼Ÿ
ç­”ï¼šä¸€éƒ¨ç§‘å¹»ç‰‡ï¼Œå«ã€Šæ˜Ÿé™…ç©¿è¶Šã€‹ï¼ŒæŒºå¥½çœ‹çš„ã€‚""",
                "expected_type": "casual"
            },
            {
                "name": "æƒ…æ„Ÿè®¿è°ˆ",
                "text": """é—®ï¼šè°ˆè°ˆè¿™æ¬¡ç»å†å¯¹ä½ çš„å½±å“ã€‚
ç­”ï¼šè¿™æ¬¡ç»å†è®©æˆ‘æˆé•¿äº†å¾ˆå¤šã€‚åˆšå¼€å§‹çš„æ—¶å€™æˆ‘å¾ˆç´§å¼ ï¼Œä¸çŸ¥é“è¯¥æ€ä¹ˆåŠã€‚ä½†æ˜¯åœ¨æœ‹å‹ä»¬çš„å¸®åŠ©ä¸‹ï¼Œæˆ‘æ…¢æ…¢æ‰¾åˆ°äº†æ–¹å‘ã€‚
é—®ï¼šç°åœ¨å›æƒ³èµ·æ¥ï¼Œä½ æœ‰ä»€ä¹ˆæ„Ÿå—ï¼Ÿ
ç­”ï¼šå¾ˆæ„Ÿæ¿€ï¼Œä¹Ÿå¾ˆåº†å¹¸è‡ªå·±åšæŒäº†ä¸‹æ¥ã€‚ç°åœ¨æƒ³æƒ³ï¼Œå›°éš¾å…¶å®ä¹Ÿæ˜¯ä¸€ç§è´¢å¯Œã€‚""",
                "expected_type": "emotional"
            },
            {
                "name": "å’¨è¯¢å¯¹è¯",
                "text": """é—®ï¼šæˆ‘æœ€è¿‘å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œä½ æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ
ç­”ï¼šå·¥ä½œå‹åŠ›å¤§æ˜¯å¾ˆæ­£å¸¸çš„ï¼Œé¦–å…ˆè¦å­¦ä¼šè°ƒèŠ‚å¿ƒæ€ã€‚æˆ‘å»ºè®®ä½ å¯ä»¥è¯•è¯•è¿åŠ¨ï¼Œæˆ–è€…æ‰¾æœ‹å‹èŠèŠã€‚
é—®ï¼šå…·ä½“åº”è¯¥æ€ä¹ˆåšå‘¢ï¼Ÿ
ç­”ï¼šæ¯”å¦‚æ¯å¤©æ™šä¸Šè·‘è·‘æ­¥ï¼Œæˆ–è€…å‘¨æœ«çº¦æœ‹å‹å‡ºå»æ”¾æ¾ä¸€ä¸‹ã€‚é‡è¦çš„æ˜¯è¦æ‰¾åˆ°é€‚åˆè‡ªå·±çš„å‡å‹æ–¹å¼ã€‚""",
                "expected_type": "consultation"
            }
        ]
    
    def _init_rule_combinations(self) -> List[Dict]:
        """åˆå§‹åŒ–è§„åˆ™ç»„åˆ"""
        return [
            {
                "name": "é»˜è®¤é…ç½®",
                "rules": []
            },
            {
                "name": "æ­£å¼ä¸“ä¸š",
                "rules": ["preserve_details", "formal_tone", "logical_grouping"]
            },
            {
                "name": "è½»æ¾è‡ªç„¶",
                "rules": ["emotion_preservation", "casual_tone"]
            },
            {
                "name": "ç®€æ´é«˜æ•ˆ",
                "rules": ["concise_expression", "logical_grouping"]
            },
            {
                "name": "è¯¦ç»†æ‰©å±•",
                "rules": ["expand_details", "preserve_details", "chronological_order"]
            }
        ]
    
    async def test_single_conversion(
        self, 
        text: str, 
        rule_config: Dict = None,
        endpoint: str = "advanced"
    ) -> Dict:
        """æµ‹è¯•å•ä¸ªè½¬æ¢"""
        
        url = f"{self.base_url}/api/v1/v2/transcription/convert/{endpoint}"
        
        payload = {"text": text}
        if rule_config:
            payload["rule_config"] = rule_config
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.post(url, json=payload)
                return response.json()
            except Exception as e:
                return {"success": False, "error": str(e)}
    
    async def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        
        print("ğŸš€ å¼€å§‹Promptä¼˜åŒ–æµ‹è¯•")
        print("=" * 60)
        
        results = []
        
        for test_case in self.test_cases:
            print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹: {test_case['name']}")
            print("-" * 40)
            
            case_results = {
                "test_case": test_case['name'],
                "original_text": test_case['text'],
                "rule_results": []
            }
            
            for rule_combo in self.rule_combinations:
                print(f"  ğŸ”§ è§„åˆ™é…ç½®: {rule_combo['name']}")
                
                rule_config = {"rules": rule_combo['rules']} if rule_combo['rules'] else None
                
                result = await self.test_single_conversion(
                    text=test_case['text'],
                    rule_config=rule_config
                )
                
                if result.get("success"):
                    converted_text = result.get("converted_text", "")
                    processing_time = result.get("processing_time", 0)
                    quality_score = result.get("quality_metrics", {}).get("overall_score", 0)
                    
                    print(f"    âœ… è½¬æ¢æˆåŠŸ | è´¨é‡è¯„åˆ†: {quality_score:.2f} | å¤„ç†æ—¶é—´: {processing_time:.1f}s")
                    print(f"    ğŸ“„ è½¬æ¢ç»“æœ: {converted_text[:100]}...")
                    
                    rule_result = {
                        "rule_name": rule_combo['name'],
                        "rules": rule_combo['rules'],
                        "success": True,
                        "converted_text": converted_text,
                        "quality_score": quality_score,
                        "processing_time": processing_time,
                        "length_change": len(converted_text) - len(test_case['text'])
                    }
                else:
                    print(f"    âŒ è½¬æ¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    rule_result = {
                        "rule_name": rule_combo['name'],
                        "rules": rule_combo['rules'],
                        "success": False,
                        "error": result.get("error", "æœªçŸ¥é”™è¯¯")
                    }
                
                case_results["rule_results"].append(rule_result)
                await asyncio.sleep(1)  # é¿å…APIè¯·æ±‚è¿‡å¿«
            
            results.append(case_results)
        
        # è¾“å‡ºæµ‹è¯•æŠ¥å‘Š
        self._generate_report(results)
        return results
    
    def _generate_report(self, results: List[Dict]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•æŠ¥å‘Šæ€»ç»“")
        print("=" * 60)
        
        for result in results:
            print(f"\nğŸ¯ {result['test_case']}")
            print("-" * 30)
            
            successful_rules = [r for r in result['rule_results'] if r['success']]
            
            if successful_rules:
                # æŒ‰è´¨é‡è¯„åˆ†æ’åº
                successful_rules.sort(key=lambda x: x['quality_score'], reverse=True)
                
                print("ğŸ“ˆ è§„åˆ™é…ç½®æ•ˆæœæ’å:")
                for i, rule in enumerate(successful_rules, 1):
                    quality = rule['quality_score']
                    time_cost = rule['processing_time']
                    length_change = rule['length_change']
                    
                    print(f"  {i}. {rule['rule_name']} - è´¨é‡: {quality:.2f} | æ—¶é—´: {time_cost:.1f}s | é•¿åº¦å˜åŒ–: {length_change:+d}")
                
                # æ¨èæœ€ä½³é…ç½®
                best_rule = successful_rules[0]
                print(f"\nğŸ† æ¨èé…ç½®: {best_rule['rule_name']}")
                print(f"   è§„åˆ™: {best_rule['rules']}")
                print(f"   è´¨é‡è¯„åˆ†: {best_rule['quality_score']:.2f}")
            else:
                print("âŒ æ‰€æœ‰è§„åˆ™é…ç½®éƒ½å¤±è´¥äº†")
        
        # æ•´ä½“ç»Ÿè®¡
        print(f"\nğŸ“Š æ•´ä½“ç»Ÿè®¡")
        print("-" * 30)
        
        total_tests = sum(len(r['rule_results']) for r in results)
        successful_tests = sum(len([rr for rr in r['rule_results'] if rr['success']]) for r in results)
        success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0
        
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"æˆåŠŸæµ‹è¯•: {successful_tests}")
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        # è§„åˆ™æ•ˆæœåˆ†æ
        rule_scores = {}
        for result in results:
            for rule_result in result['rule_results']:
                if rule_result['success']:
                    rule_name = rule_result['rule_name']
                    if rule_name not in rule_scores:
                        rule_scores[rule_name] = []
                    rule_scores[rule_name].append(rule_result['quality_score'])
        
        print(f"\nğŸ–ï¸ è§„åˆ™é…ç½®å¹³å‡è´¨é‡æ’å:")
        rule_averages = {name: sum(scores)/len(scores) for name, scores in rule_scores.items()}
        sorted_rules = sorted(rule_averages.items(), key=lambda x: x[1], reverse=True)
        
        for i, (rule_name, avg_score) in enumerate(sorted_rules, 1):
            print(f"  {i}. {rule_name}: {avg_score:.2f}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = PromptOptimizationTester()
    await tester.run_comprehensive_test()


if __name__ == "__main__":
    asyncio.run(main()) 